import pandas as pd
import shutil
import logging
import xlwt
from pathlib import Path
from datetime import datetime
from typing import List, Generator, Dict, Optional, Tuple, Any
import time
import os
# --- è¨­å®š Log ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S',
    handlers=[
        logging.FileHandler("app.log", encoding='utf-8'), # å¯«å…¥æª”æ¡ˆï¼Œæª”åå«åš app.log
        logging.StreamHandler()                           # é¡¯ç¤ºåœ¨è¢å¹•ä¸Š
    ]
)
logger = logging.getLogger(__name__)

# --- è¨­å®šç®¡ç†å™¨ (å–®ä¸€è¡¨æ ¼æ¨¡å¼) ---
class ConfigManager:
    def __init__(self, base_dir: Path):
        self.settings_dir = base_dir / "settings"
        self.settings_file = self.settings_dir / "supplier_config.xlsx"
        self.settings_dir.mkdir(parents=True, exist_ok=True)
        
        # é è¨­ç¯„ä¾‹ (ä¾ç…§ä½ çš„è¦æ±‚ï¼šä¾›æ‡‰å•†åç¨±åªæ˜¯é¡¯ç¤ºç”¨)
        self.DEFAULT_DATA = [
            {
                "ä¾›æ‡‰å•†åç¨±": "å¯ç¾å¡‘æ–™åˆ¶å“æœ‰é™å…¬å¸", # é€™æ˜¯çµ¦äººçœ‹çš„ ID
                "è²¨å“æ¢ç¢¼": "æ¡å½¢ç ",             # å¿…é ˆå®Œå…¨åŒ¹é…æ”¶æ“šè£¡çš„æ¬„ä½å
                "å…¥è²¨åƒ¹": "å•ä»·",
                "å…¥è²¨é‡": "æ•°é‡",
                "è²¨å“åç¨±": "è´§å“åç§°åŠè§„æ ¼å‹å·",
                "æˆæœ¬ä¹˜ä»¥1.2": "æ˜¯"
            }
        ]

    def load_config(self) -> pd.DataFrame:
        """è®€å– Excel è¨­å®š"""
        if not self.settings_file.exists():
            self._create_default_config()
        
        try:
            df = pd.read_excel(self.settings_file)
            # ç¢ºä¿æ¬„ä½éƒ½æ˜¯å­—ä¸²ï¼Œä¸¦å»é™¤å‰å¾Œç©ºç™½
            df = df.astype(str).apply(lambda x: x.str.strip())
            logger.info("âœ… ä¾›æ‡‰å•†è¨­å®šæª”è®€å–æˆåŠŸ")
            return df
        except Exception as e:
            logger.error(f"âŒ è®€å–è¨­å®šæª”å¤±æ•—: {e}")
            return pd.DataFrame(self.DEFAULT_DATA)

    def _create_default_config(self):
        """ç”¢ç”Ÿçµ¦å“¡å·¥å¡«å¯«çš„ Excel"""
        logger.info(f"âš ï¸ å»ºç«‹é è¨­è¨­å®šæª”: {self.settings_file}")
        df = pd.DataFrame(self.DEFAULT_DATA)
        cols = ["ä¾›æ‡‰å•†åç¨±", "è²¨å“æ¢ç¢¼", "å…¥è²¨åƒ¹", "å…¥è²¨é‡", "è²¨å“åç¨±", "æˆæœ¬ä¹˜ä»¥1.2"]
        df = df[cols]
        df.to_excel(self.settings_file, index=False)


# --- è®€å–å™¨ ---
class BatchReceiptLoader:
    def __init__(self, base_dir: str = "workspace"):
        self.base_path = Path(base_dir)
        self.pending_path = self.base_path / "pending"
        self.processed_path = self.base_path / "processed"

        # æª¢æŸ¥ä¸¦å»ºç«‹è³‡æ–™å¤¾
        if not self.pending_path.exists() or not self.processed_path.exists():
            self.pending_path.mkdir(parents=True, exist_ok=True)
            self.processed_path.mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸ“‚ å·¥ä½œç›®éŒ„è¨­å®šå®Œæˆï¼š")
            logger.info(f"   - å¾…è™•ç†: {self.pending_path}")
            logger.info(f"   - å·²æ­¸æª”: {self.processed_path}")


    def get_pending_files(self) -> Generator[Path, None, None]:
        """
        æƒæ 'pending' è³‡æ–™å¤¾ï¼Œæ‰¾å‡ºæ‰€æœ‰ Excel (.xls, .xlsx) å’Œ CSV æª”æ¡ˆ
        """
        # æ”¯æ´çš„å‰¯æª”å
        extensions = ['*.xlsx', '*.xls', '*.csv']
        files_found = False
        
        for ext in extensions:
            # glob æœƒæœå°‹æ‰€æœ‰ç¬¦åˆå‰¯æª”åçš„æª”æ¡ˆ
            for file_path in self.pending_path.glob(ext):
                # å¿½ç•¥ Excel æ‰“é–‹æ™‚ç”¢ç”Ÿçš„æš«å­˜æª” (æª”åä»¥ ~$ é–‹é ­)
                if not file_path.name.startswith('~$'):
                    files_found = True
                    yield file_path
        
        if not files_found:
            logger.warning("âš ï¸ 'pending' è³‡æ–™å¤¾å…§æ²’æœ‰ Excel æˆ– CSV æª”æ¡ˆ")

    def archive_file(self, file_path: Path):
        """æ­¸æª”åŸå§‹æ–‡ä»¶ (è™•ç†æª”æ¡ˆè¢«ä½”ç”¨å•é¡Œ)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        new_name = f"{file_path.stem}_{timestamp}{file_path.suffix}"
        destination = self.processed_path / new_name

        while True:
            try:
                shutil.move(str(file_path), str(destination))
                logger.info(f"ğŸ“¦ å·²æ­¸æª”: {new_name}")
                break # æˆåŠŸç§»å‹•å¾Œè·³å‡ºè¿´åœˆ
            except PermissionError:
                logger.warning(f"âš ï¸ ç„¡æ³•ç§»å‹•æª”æ¡ˆ (è¢«ä½”ç”¨): {file_path.name}")
                print(f"\nğŸ›‘ éŒ¯èª¤ï¼šæª”æ¡ˆ '{file_path.name}' æ­£è¢« Excel é–‹å•Ÿä¸­ï¼")
                input("ğŸ‘‰ è«‹é—œé–‰è©²æª”æ¡ˆï¼Œç„¶å¾ŒæŒ‰ [Enter] éµé‡è©¦...")
                logger.info("ğŸ”„ ä½¿ç”¨è€…å˜—è©¦é‡è©¦æ­¸æª”...")
            except Exception as e:
                logger.error(f"âŒ æ­¸æª”å¤±æ•— (æœªçŸ¥éŒ¯èª¤): {e}")
                break # å…¶ä»–éŒ¯èª¤ç›´æ¥æ”¾æ£„ï¼Œé¿å…ç„¡çª®è¿´åœˆ

    def smart_load(self, file_path: Path, expected_keywords: List[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:
        try:
            logger.info(f"ğŸ“– è®€å–: {file_path.name}")
            # 1. å…ˆè®€å‰ 20 è¡Œç”¨ä¾†æ‰¾ Header
            if file_path.suffix == '.csv':
                 df_raw = pd.read_csv(file_path, header=None, nrows=20)
            else:
                df_raw = pd.read_excel(file_path, header=None, nrows=20)
            
            header_idx = self._find_header_row(df_raw, expected_keywords)
            
            if header_idx == -1:
                logger.warning(f"âš ï¸ {file_path.name}: æ‰¾ä¸åˆ°æ¨™é¡Œåˆ—ï¼Œè·³é")
                return pd.DataFrame(), pd.DataFrame()

            # 2. æ­£å¼è®€å–æ•¸æ“š
            # ä¿®æ”¹ï¼šåŠ å…¥ dtype=str å¼·åˆ¶æ‰€æœ‰æ¬„ä½ä»¥ã€Œç´”æ–‡å­—ã€è®€å–ï¼Œä¿ç•™é–‹é ­çš„ 0ï¼Œé¿å…è®Šæˆæ•¸å­—
            if file_path.suffix == '.csv':
                df_data = pd.read_csv(file_path, header=header_idx, dtype=str)
            else:
                df_data = pd.read_excel(file_path, header=header_idx, dtype=str)
                
            df_data = df_data.dropna(how='all', axis=0).dropna(how='all', axis=1)
            return df_raw, df_data

        except Exception as e:
            logger.error(f"âŒ è®€å–éŒ¯: {e}")
            return pd.DataFrame(), pd.DataFrame()

    def _find_header_row(self, df: pd.DataFrame, keywords: List[str]) -> int:
        max_score = 0
        best_idx = -1
        for idx, row in df.iterrows():
            row_str = " ".join(row.astype(str)).lower()
            score = 0
            for key in keywords:
                # åªè¦å‘½ä¸­å…¶ä¸­ä¸€å€‹é—œéµå­—
                if key and key.lower() in row_str:
                    score += 1
            
            # ä¿®æ­£ï¼šå¿…é ˆå‘½ä¸­è‡³å°‘ 2 å€‹é—œéµå­—æ‰ç®—æ‰¾åˆ°
            if score > max_score and score >= 2:
                max_score = score
                best_idx = idx
        return best_idx




# --- æ¸…æ´—å™¨ ---
class ReceiptCleaner:
    def __init__(self, config_df: pd.DataFrame):
        self.config_df = config_df
        
    def identify_supplier_by_columns(self, file_columns: List[str]) -> Tuple[Optional[pd.Series], str]:
        """
        æ ¸å¿ƒé‚è¼¯ï¼šæª¢æŸ¥æ”¶æ“šçš„æ¨™é¡Œåˆ—ï¼Œæ˜¯å¦åŒ…å«è¨­å®šæª”ä¸­æŸå®¶å» å•†çš„æ‰€æœ‰ 4 å€‹é—œéµæ¬„ä½
        """
        if self.config_df.empty:
            return None, "Unknown"

        file_cols_lower = {str(c).strip().lower() for c in file_columns}

        for _, row in self.config_df.iterrows():
            required_cols = [
                str(row['è²¨å“æ¢ç¢¼']).strip().lower(),
                str(row['å…¥è²¨åƒ¹']).strip().lower(),
                str(row['å…¥è²¨é‡']).strip().lower(),
                str(row['è²¨å“åç¨±']).strip().lower()
            ]
            supplier_name = row['ä¾›æ‡‰å•†åç¨±']

            # æª¢æŸ¥æ˜¯å¦ 4 å€‹æ¬„ä½éƒ½å­˜åœ¨
            if set(required_cols).issubset(file_cols_lower):
                logger.info(f"   ğŸ¯ æ¬„ä½å®Œå…¨åŒ¹é… -> è­˜åˆ¥ç‚º: {supplier_name}")
                return row, supplier_name
        
        return None, "New Supplier"

    def process(self, df: pd.DataFrame) -> Optional[pd.DataFrame]:
        # 1. è­˜åˆ¥
        supplier_config, supplier_name = self.identify_supplier_by_columns(df.columns)
        
        # 2. æ”¹å (åªæœ‰è­˜åˆ¥æˆåŠŸæ‰æ”¹åï¼Œä¸äº‚çŒœ)
        if supplier_config is not None:
            df = self._rename_columns_strict(df, supplier_config)
        else:
            logger.warning("   âš ï¸ ç„¡æ³•è­˜åˆ¥ä¾›æ‡‰å•† (æ¬„ä½ç‰¹å¾µä¸ç¬¦)")
            logger.info(f"      æ”¶æ“šæ¬„ä½: {list(df.columns)}")
            return None # ç›´æ¥è¿”å› Noneï¼Œä¸ç¹¼çºŒè™•ç†

        # 3. æª¢æŸ¥å¿…è¦æ¬„ä½
        required_cols = ["è²¨å“æ¢ç¢¼", "å…¥è²¨åƒ¹", "å…¥è²¨é‡", "è²¨å“åç¨±"]
        missing = [c for c in required_cols if c not in df.columns]
        if missing:
            logger.error(f"âŒ ç¼ºå°‘å¿…è¦æ¬„ä½: {missing}")
            return None

        df = df[required_cols].copy()
        
        # 4. åŸºç¤æ¸…æ´—
        # ä¿®æ”¹ï¼šæ­£å‰‡è¡¨é”å¼æ”¹ç‚º r'\.0+$'ï¼Œæ„æ€æ˜¯ã€Œå°æ•¸é»å¾Œè·Ÿè‘—ä¸€å€‹æˆ–å¤šå€‹ 0ã€éƒ½è¦åˆªæ‰
        # é€™æ¨£å¯ä»¥åŒæ™‚è™•ç† .0, .00, .000 ç­‰æƒ…æ³
        df['è²¨å“æ¢ç¢¼'] = df['è²¨å“æ¢ç¢¼'].astype(str).str.strip().str.replace(r'\.0+$', '', regex=True)
        for col in ['å…¥è²¨åƒ¹', 'å…¥è²¨é‡']:
            df[col] = df[col].astype(str).str.replace(r'[^\d.]', '', regex=True)
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        df['å…¥è²¨é‡'] = df['å…¥è²¨é‡'].astype(int)
        
        # 5. æˆæœ¬åŠ æˆé‚è¼¯
        multiplier_flag = str(supplier_config.get('æˆæœ¬ä¹˜ä»¥1.2', '')).strip()
        if multiplier_flag in ['æ˜¯', 'Yes', 'TRUE', 'True', '1']:
            logger.info("   ğŸ’° åŸ·è¡Œæˆæœ¬åŠ æˆ (x1.2)")
            df['å…¥è²¨åƒ¹'] = df['å…¥è²¨åƒ¹'] * 1.2
            df['å…¥è²¨åƒ¹'] = df['å…¥è²¨åƒ¹'].round(2)

        # 6. è£œé½Šæ¬„ä½
        df['ä¾›æ‡‰å•†åç¨±'] = ''
        df['åº—è™Ÿ'] = 'S1'
        df['å…¥è²¨æ—¥æœŸ'] = datetime.now().strftime('%Y%m%d')
        df['æ”¶æ“šå–®è™Ÿ'] = ''
        df['ä¾›æ‡‰å•†ç·¨è™Ÿ'] = '001'
        df['å‚™è¨»'] = ''
        df['ç‹€æ…‹'] = ''
        df['è²¨å“ç·¨è™Ÿ'] = df['è²¨å“æ¢ç¢¼']

        df = df[ (df['è²¨å“æ¢ç¢¼'] != '') & (df['è²¨å“æ¢ç¢¼'] != 'nan') & (df['å…¥è²¨é‡'] > 0) ]
        return df

    def _rename_columns_strict(self, df: pd.DataFrame, config: pd.Series) -> pd.DataFrame:
        """æ ¹æ“šè¨­å®šæª”ç²¾ç¢ºæ”¹å"""
        target_map = {
            "è²¨å“æ¢ç¢¼": config.get("è²¨å“æ¢ç¢¼"),
            "å…¥è²¨åƒ¹": config.get("å…¥è²¨åƒ¹"),
            "å…¥è²¨é‡": config.get("å…¥è²¨é‡"),
            "è²¨å“åç¨±": config.get("è²¨å“åç¨±")
        }

        reverse_map = {}
        for target, source in target_map.items():
            if pd.notna(source):
                reverse_map[str(source).strip().lower()] = target
        
        new_columns = {}
        for col in df.columns:
            if str(col).strip().lower() in reverse_map:
                new_columns[col] = reverse_map[str(col).strip().lower()]
        
        return df.rename(columns=new_columns)


# --- æª”æ¡ˆè¼¸å‡ºå™¨ ---
class ReceiptExporter:
    def __init__(self, base_dir: str = "workspace"):
        self.output_root = Path(base_dir) / "output"

        self.pos_dir = self.output_root / "pos_import" # å­˜æ”¾ POS æ ¼å¼çš„ XLS
        
        self.pos_dir.mkdir(parents=True, exist_ok=True)

    def save_pos_excel(self, df: pd.DataFrame, original_filename: str):
        """ç”¢ç”Ÿ POS ç³»çµ±å°ˆç”¨çš„èˆŠç‰ˆ .xls æ ¼å¼ (å­—ä¸²æ¨¡å¼)"""
        # å®šç¾©æ¨¡æ¿ (ä¾ç…§ä½ çš„éœ€æ±‚)
        # éµå€¼ (0-12) å°æ‡‰ Excel çš„ç¬¬ A-M æ¬„
        Instock_template = {
            0: [
                'MBA POS å…¥è²¨è¡¨', '', 
                'è«‹ä¸è¦ä¿®æ”¹æ­¤å…¥è²¨è¡¨ä¹‹æ ¼å¼!! å¦‚æ­¤å…¥è²¨è¡¨ä¹‹æ ¼å¼è¢«ä¿®æ”¹, å¯èƒ½æœƒå°è‡´ç³»çµ±ä¸èƒ½åŒ¯å…¥æ­¤è¡¨ä¸­çš„è³‡æ–™!!', 
                'ç³»çµ±åªæœƒæª¢æŸ¥ä¸¦æŠŠ è²¨è™Ÿ/ æ¢ç¢¼,  å…¥è²¨åƒ¹,  å…¥è²¨é‡, åº—è™Ÿ, å…¥è²¨æ—¥æœŸ, æ”¶æ“šå–®è™Ÿ åŠ ä¾›æ‡‰å•†ç·¨è™Ÿ  è³‡æ–™åŒ¯å…¥ç³»çµ±.  è²¨å“åŠä¾›æ‡‰å•†åç¨±åªä¾›å®¢äººä½œåƒè€ƒ.', 
                'å¯åœ¨ä¸‹è¡¨ åªè¼¸å…¥è²¨å“ç·¨è™Ÿæˆ–è²¨ å“æ¢ç¢¼.   å¦‚åœ¨ä¸‹è¡¨åŒæ™‚è¼¸å…¥è²¨å“ç·¨è™ŸåŠè²¨å“æ¢ç¢¼, ç³»çµ±æœƒä»¥è²¨å“ç·¨è™Ÿç‚ºæº–.', 
                'è«‹ç•™æ„, å…¥è²¨æ—¥æœŸæ ¼å¼ç‚º (å¹´å¹´å¹´å¹´æœˆæœˆæ—¥æ—¥), å³ä»Šå¤©çš„æ—¥æœŸç‚º 20250315', 
                '', '', '', '', '', '', '', '', 'è²¨å“ç·¨è™Ÿ'
            ],
            1: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'è²¨å“æ¢ç¢¼'],
            2: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'è²¨å“åç¨±'],
            3: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'å…¥è²¨åƒ¹'],
            4: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'å…¥è²¨é‡'],
            5: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'åº—è™Ÿ'],
            6: ['Ver:3.2', '', '', '', '', '', '', '', '', '', '', '', '', '', 'å…¥è²¨æ—¥æœŸ'],
            7: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'æ”¶æ“šå–®è™Ÿ'],
            8: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'ä¾›æ‡‰å•†ç·¨è™Ÿ'],
            9: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'ä¾›æ‡‰å•†åç¨±'],
            10: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'å‚™è¨»'],
            11: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'ç‹€æ…‹'],
            12: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'ç³»çµ±å‚™è¨»']
        }

        # 1. æº–å‚™ POS ç³»çµ±è¦æ±‚çš„æ¬„ä½é †åº (å‹™å¿…èˆ‡ Template Key 0~12 å°æ‡‰)
        target_columns = [
            'è²¨å“ç·¨è™Ÿ', 'è²¨å“æ¢ç¢¼', 'è²¨å“åç¨±', 'å…¥è²¨åƒ¹', 'å…¥è²¨é‡',
            'åº—è™Ÿ', 'å…¥è²¨æ—¥æœŸ', 'æ”¶æ“šå–®è™Ÿ', 'ä¾›æ‡‰å•†ç·¨è™Ÿ', 'ä¾›æ‡‰å•†åç¨±',
            'å‚™è¨»', 'ç‹€æ…‹', 'ç³»çµ±å‚™è¨»'
        ]

        # ç¢ºä¿ DataFrame æŒ‰ç…§é€™å€‹é †åºæ’åˆ—ï¼Œç¼ºå°‘çš„æ¬„ä½æœƒåœ¨ Cleaner éšæ®µè£œé½Š
        # è‹¥æœ‰è¬ä¸€ç¼ºå°‘çš„ï¼Œé€™è£¡è£œä¸Šç©ºå­—ä¸²ä»¥å…å ±éŒ¯
        for col in target_columns:
            if col not in df.columns:
                df[col] = ''
        
        df_export = df[target_columns].copy()

        # 2. å»ºç«‹ Excel
        workbook = xlwt.Workbook(encoding='utf-8')
        sheet = workbook.add_sheet('Sheet1')

        # 3. å¯«å…¥æ¨¡æ¿ (Template)
        # Template çµæ§‹ï¼šKey æ˜¯ Column Indexï¼ŒValue æ˜¯è©² Column çš„ Rows List
        for col_idx, row_data_list in Instock_template.items():
            for row_idx, cell_value in enumerate(row_data_list):
                # å¼·åˆ¶è½‰å­—ä¸²
                sheet.write(row_idx, col_idx, str(cell_value))

        # 4. å¯«å…¥æ•¸æ“š (Data)
        # è³‡æ–™å¾æ¨¡æ¿æœ€é•·çš„é‚£ä¸€è¡Œä¹‹å¾Œé–‹å§‹å¯«å…¥
        start_row = max(len(row) for row in Instock_template.values())
        
        for i, row_data in enumerate(df_export.values):
            for j, cell_value in enumerate(row_data):
                # å¼·åˆ¶è½‰å­—ä¸² (str)ï¼Œç¢ºä¿ POS ç³»çµ±ç›¸å®¹æ€§
                sheet.write(start_row + i, j, str(cell_value))

        # 5. å­˜æª”
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"POS_{Path(original_filename).stem}_{timestamp}.xls"
        save_path = self.pos_dir / filename
        
        workbook.save(str(save_path))
        logger.info(f"   ğŸ’¾ POS åŒ¯å…¥æª”: {filename}")

def main():

    base_dir = "workspace"
    # 1. è®€å–è¨­å®š
    config_mgr = ConfigManager(Path(base_dir))
    config_df = config_mgr.load_config()
    
    loader = BatchReceiptLoader(base_dir)
    cleaner = ReceiptCleaner(config_df)
    exporter = ReceiptExporter(base_dir)

    input_stock = "data/processed/DetailGoodsStockToday.csv"
    if not os.path.exists(input_stock):
        logger.error("âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æ•¸æ“šæºã€‚")
        return
    


    logger.info("ğŸš€ é–‹å§‹æ‰¹æ¬¡è™•ç†...")
    
    # æœå°‹é—œéµå­—ï¼šå¾è¨­å®šæª”è£¡çš„ 4 å€‹é—œéµæ¬„ä½æŠ“å­—
    search_keywords = []
    if not config_df.empty:
        target_cols = ["è²¨å“æ¢ç¢¼", "å…¥è²¨åƒ¹", "å…¥è²¨é‡", "è²¨å“åç¨±"]
        for col in target_cols:
            if col in config_df.columns:
                keywords = config_df[col].dropna().unique().tolist()
                search_keywords.extend([k for k in keywords if k.lower() != 'nan' and k.strip()])
    
    # è‹¥ Config æ²’æ±è¥¿ï¼Œçµ¦å€‹åŸºæœ¬é è¨­å€¼ä»¥å…ç¨‹å¼è·‘ä¸å‹•
    if not search_keywords:
        logger.warning("âš ï¸ Config ä¸­ç„¡é—œéµå­—ï¼Œè«‹è¨­å®šä¾›æ‡‰å•†è¨­å®šæª”ï¼")

        # 2. é–‹å§‹è·‘æª”æ¡ˆ
        for file_path in loader.get_pending_files():
            raw_header_df, raw_data_df = loader.smart_load(file_path, search_keywords)
            
            if not raw_data_df.empty:
                clean_df = cleaner.process(raw_data_df)
                
                if clean_df is not None:
                    # è¼¸å‡º POS å°ˆç”¨ Excel
                    exporter.save_pos_excel(clean_df, file_path.name)
                    
                    loader.archive_file(file_path)
                else:
                    logger.error("   âŒ æ¸…æ´—å¤±æ•— (æœªè­˜åˆ¥æˆ–æ ¼å¼éŒ¯èª¤)")
            
        print("-" * 30)
    input("æŒ‰ Enter éµçµæŸç¨‹å¼...")
# --- ä¸»ç¨‹å¼ ---
if __name__ == "__main__":
    main()