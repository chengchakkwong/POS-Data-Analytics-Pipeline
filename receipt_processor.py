import pandas as pd
import shutil
import logging
import xlwt
from pathlib import Path
from datetime import datetime
from typing import List, Generator, Dict, Optional, Tuple, Any
import time
import os
import logger_config  # å°å…¥çµ±ä¸€çš„æ—¥èªŒé…ç½®

# ä½¿ç”¨çµ±ä¸€çš„æ—¥èªŒé…ç½®
logger = logging.getLogger(__name__)

# --- è¨­å®šç®¡ç†å™¨ (å–®ä¸€è¡¨æ ¼æ¨¡å¼) ---
class ConfigManager:
    def __init__(self, base_dir: Path):
        self.settings_dir = base_dir / "settings"
        self.settings_file = self.settings_dir / "supplier_config.xlsx"
        self.settings_dir.mkdir(parents=True, exist_ok=True)
        
        # é è¨­ç¯„ä¾‹ (ä¾ç…§ä½ çš„è¦æ±‚ï¼šä¾›æ‡‰å•†åç¨±åªæ˜¯é¡¯ç¤ºç”¨)
        self.DEFAULT_DATA = [
            {
                "ä¾›æ‡‰å•†åç¨±": "å¯ç¾å¡‘æ–™åˆ¶å“æœ‰é™å…¬å¸", # é€™æ˜¯çµ¦äººçœ‹çš„ ID
                "è²¨å“æ¢ç¢¼": "æ¡å½¢ç ",             # å¿…é ˆå®Œå…¨åŒ¹é…æ”¶æ“šè£¡çš„æ¬„ä½å
                "å…¥è²¨åƒ¹": "å•ä»·",
                "å…¥è²¨é‡": "æ•°é‡",
                "è²¨å“åç¨±": "è´§å“åç§°åŠè§„æ ¼å‹å·",
                "æˆæœ¬ä¹˜ä»¥1.2": "æ˜¯"
            }
        ]

    def load_config(self) -> pd.DataFrame:
        """è®€å– Excel è¨­å®š"""
        if not self.settings_file.exists():
            self._create_default_config()
        
        try:
            df = pd.read_excel(self.settings_file)
            # ç¢ºä¿æ¬„ä½éƒ½æ˜¯å­—ä¸²ï¼Œä¸¦å»é™¤å‰å¾Œç©ºç™½
            df = df.astype(str).apply(lambda x: x.str.strip())
            logger.info("âœ… ä¾›æ‡‰å•†è¨­å®šæª”è®€å–æˆåŠŸ")
            return df
        except Exception as e:
            logger.error(f"âŒ è®€å–è¨­å®šæª”å¤±æ•—: {e}")
            return pd.DataFrame(self.DEFAULT_DATA)

    def _create_default_config(self):
        """ç”¢ç”Ÿçµ¦å“¡å·¥å¡«å¯«çš„ Excel"""
        logger.info(f"âš ï¸ å»ºç«‹é è¨­è¨­å®šæª”: {self.settings_file}")
        df = pd.DataFrame(self.DEFAULT_DATA)
        cols = ["ä¾›æ‡‰å•†åç¨±", "è²¨å“æ¢ç¢¼", "å…¥è²¨åƒ¹", "å…¥è²¨é‡", "è²¨å“åç¨±", "æˆæœ¬ä¹˜ä»¥1.2"]
        df = df[cols]
        df.to_excel(self.settings_file, index=False)


# --- è®€å–å™¨ ---
class BatchReceiptLoader:
    def __init__(self, base_dir: str = "workspace"):
        self.base_path = Path(base_dir)
        self.pending_path = self.base_path / "pending"
        self.processed_path = self.base_path / "processed"

        # æª¢æŸ¥ä¸¦å»ºç«‹è³‡æ–™å¤¾
        if not self.pending_path.exists() or not self.processed_path.exists():
            self.pending_path.mkdir(parents=True, exist_ok=True)
            self.processed_path.mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸ“‚ å·¥ä½œç›®éŒ„è¨­å®šå®Œæˆï¼š")
            logger.info(f"   - å¾…è™•ç†: {self.pending_path}")
            logger.info(f"   - å·²æ­¸æª”: {self.processed_path}")


    def get_pending_files(self) -> Generator[Path, None, None]:
        """
        æƒæ 'pending' è³‡æ–™å¤¾ï¼Œæ‰¾å‡ºæ‰€æœ‰ Excel (.xls, .xlsx) å’Œ CSV æª”æ¡ˆ
        """
        # æ”¯æ´çš„å‰¯æª”å
        extensions = ['*.xlsx', '*.xls', '*.csv']
        files_found = False
        
        for ext in extensions:
            # glob æœƒæœå°‹æ‰€æœ‰ç¬¦åˆå‰¯æª”åçš„æª”æ¡ˆ
            for file_path in self.pending_path.glob(ext):
                # å¿½ç•¥ Excel æ‰“é–‹æ™‚ç”¢ç”Ÿçš„æš«å­˜æª” (æª”åä»¥ ~$ é–‹é ­)
                if not file_path.name.startswith('~$'):
                    files_found = True
                    yield file_path
        
        if not files_found:
            logger.warning("âš ï¸ 'pending' è³‡æ–™å¤¾å…§æ²’æœ‰ Excel æˆ– CSV æª”æ¡ˆ")

    def archive_file(self, file_path: Path):
        """æ­¸æª”åŸå§‹æ–‡ä»¶ (è™•ç†æª”æ¡ˆè¢«ä½”ç”¨å•é¡Œ)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        new_name = f"{file_path.stem}_{timestamp}{file_path.suffix}"
        destination = self.processed_path / new_name

        while True:
            try:
                shutil.move(str(file_path), str(destination))
                logger.info(f"ğŸ“¦ å·²æ­¸æª”: {new_name}")
                break # æˆåŠŸç§»å‹•å¾Œè·³å‡ºè¿´åœˆ
            except PermissionError:
                logger.warning(f"âš ï¸ ç„¡æ³•ç§»å‹•æª”æ¡ˆ (è¢«ä½”ç”¨): {file_path.name}")
                logger.error(f"ğŸ›‘ éŒ¯èª¤ï¼šæª”æ¡ˆ '{file_path.name}' æ­£è¢« Excel é–‹å•Ÿä¸­ï¼")
                logger.info("ğŸ‘‰ è«‹é—œé–‰è©²æª”æ¡ˆï¼Œç„¶å¾ŒæŒ‰ [Enter] éµé‡è©¦...")
                input()  # ç­‰å¾…ç”¨æˆ¶è¼¸å…¥ï¼Œä½†ä¸è¼¸å‡ºåˆ°çµ‚ç«¯ï¼ˆé€šé logger å·²è¨˜éŒ„ï¼‰
                logger.info("ğŸ”„ ä½¿ç”¨è€…å˜—è©¦é‡è©¦æ­¸æª”...")
            except Exception as e:
                logger.error(f"âŒ æ­¸æª”å¤±æ•— (æœªçŸ¥éŒ¯èª¤): {e}")
                break # å…¶ä»–éŒ¯èª¤ç›´æ¥æ”¾æ£„ï¼Œé¿å…ç„¡çª®è¿´åœˆ

    def smart_load(self, file_path: Path, expected_keywords: List[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:
        try:
            logger.info(f"ğŸ“– è®€å–: {file_path.name}")
            # 1. å…ˆè®€å‰ 20 è¡Œç”¨ä¾†æ‰¾ Header
            if file_path.suffix == '.csv':
                 df_raw = pd.read_csv(file_path, header=None, nrows=20)
            else:
                df_raw = pd.read_excel(file_path, header=None, nrows=20)
            
            header_idx = self._find_header_row(df_raw, expected_keywords)
            
            if header_idx == -1:
                logger.warning(f"âš ï¸ {file_path.name}: æ‰¾ä¸åˆ°æ¨™é¡Œåˆ—ï¼Œè·³é")
                return pd.DataFrame(), pd.DataFrame()

            # 2. æ­£å¼è®€å–æ•¸æ“š
            # ä¿®æ”¹ï¼šåŠ å…¥ dtype=str å¼·åˆ¶æ‰€æœ‰æ¬„ä½ä»¥ã€Œç´”æ–‡å­—ã€è®€å–ï¼Œä¿ç•™é–‹é ­çš„ 0ï¼Œé¿å…è®Šæˆæ•¸å­—
            if file_path.suffix == '.csv':
                df_data = pd.read_csv(file_path, header=header_idx, dtype=str)
            else:
                df_data = pd.read_excel(file_path, header=header_idx, dtype=str)
                
            df_data = df_data.dropna(how='all', axis=0).dropna(how='all', axis=1)
            return df_raw, df_data

        except Exception as e:
            logger.error(f"âŒ è®€å–éŒ¯: {e}")
            return pd.DataFrame(), pd.DataFrame()

    def _find_header_row(self, df: pd.DataFrame, keywords: List[str]) -> int:
        max_score = 0
        best_idx = -1
        for idx, row in df.iterrows():
            row_str = " ".join(row.astype(str)).lower()
            score = 0
            for key in keywords:
                # åªè¦å‘½ä¸­å…¶ä¸­ä¸€å€‹é—œéµå­—
                if key and key.lower() in row_str:
                    score += 1
            
            # ä¿®æ­£ï¼šå¿…é ˆå‘½ä¸­è‡³å°‘ 2 å€‹é—œéµå­—æ‰ç®—æ‰¾åˆ°
            if score > max_score and score >= 2:
                max_score = score
                best_idx = idx
        return best_idx




# --- æ¸…æ´—å™¨ ---
class ReceiptCleaner:
    def __init__(self, config_df: pd.DataFrame):
        self.config_df = config_df
        
    def identify_supplier_by_columns(self, file_columns: List[str]) -> Tuple[Optional[pd.Series], str]:
        """
        æ ¸å¿ƒé‚è¼¯ï¼šæª¢æŸ¥æ”¶æ“šçš„æ¨™é¡Œåˆ—ï¼Œæ˜¯å¦åŒ…å«è¨­å®šæª”ä¸­æŸå®¶å» å•†çš„æ‰€æœ‰ 4 å€‹é—œéµæ¬„ä½
        """
        if self.config_df.empty:
            return None, "Unknown"

        file_cols_lower = {str(c).strip().lower() for c in file_columns}

        for _, row in self.config_df.iterrows():
            required_cols = [
                str(row['è²¨å“æ¢ç¢¼']).strip().lower(),
                str(row['å…¥è²¨åƒ¹']).strip().lower(),
                str(row['å…¥è²¨é‡']).strip().lower(),
                str(row['è²¨å“åç¨±']).strip().lower()
            ]
            supplier_name = row['ä¾›æ‡‰å•†åç¨±']

            # æª¢æŸ¥æ˜¯å¦ 4 å€‹æ¬„ä½éƒ½å­˜åœ¨
            if set(required_cols).issubset(file_cols_lower):
                logger.info(f"   ğŸ¯ æ¬„ä½å®Œå…¨åŒ¹é… -> è­˜åˆ¥ç‚º: {supplier_name}")
                return row, supplier_name
        
        return None, "New Supplier"

    def process(self, df: pd.DataFrame) -> Tuple[Optional[pd.DataFrame], str]:
        """
        è™•ç†æ”¶æ“šæ•¸æ“š
        
        Returns:
            Tuple[Optional[pd.DataFrame], str]: 
            - DataFrame: æ¸…æ´—å¾Œçš„æ•¸æ“šï¼Œå¦‚æœè™•ç†å¤±æ•—å‰‡è¿”å› None
            - str: è­˜åˆ¥åˆ°çš„ä¾›æ‡‰å•†åç¨±ï¼Œå¦‚æœç„¡æ³•è­˜åˆ¥å‰‡è¿”å›ç©ºå­—ä¸²
        """
        # 1. è­˜åˆ¥
        supplier_config, supplier_name = self.identify_supplier_by_columns(df.columns)
        
        # 2. æ”¹å (åªæœ‰è­˜åˆ¥æˆåŠŸæ‰æ”¹åï¼Œä¸äº‚çŒœ)
        if supplier_config is not None:
            df = self._rename_columns_strict(df, supplier_config)
        else:
            logger.warning("   âš ï¸ ç„¡æ³•è­˜åˆ¥ä¾›æ‡‰å•† (æ¬„ä½ç‰¹å¾µä¸ç¬¦)")
            logger.info(f"      æ”¶æ“šæ¬„ä½: {list(df.columns)}")
            return None, "" # ç›´æ¥è¿”å› Noneï¼Œä¸ç¹¼çºŒè™•ç†

        # 3. æª¢æŸ¥å¿…è¦æ¬„ä½
        required_cols = ["è²¨å“æ¢ç¢¼", "å…¥è²¨åƒ¹", "å…¥è²¨é‡", "è²¨å“åç¨±"]
        missing = [c for c in required_cols if c not in df.columns]
        if missing:
            logger.error(f"âŒ ç¼ºå°‘å¿…è¦æ¬„ä½: {missing}")
            return None, supplier_name

        df = df[required_cols].copy()
        
        # 4. åŸºç¤æ¸…æ´—
        # ä¿®æ”¹ï¼šæ­£å‰‡è¡¨é”å¼æ”¹ç‚º r'\.0+$'ï¼Œæ„æ€æ˜¯ã€Œå°æ•¸é»å¾Œè·Ÿè‘—ä¸€å€‹æˆ–å¤šå€‹ 0ã€éƒ½è¦åˆªæ‰
        # é€™æ¨£å¯ä»¥åŒæ™‚è™•ç† .0, .00, .000 ç­‰æƒ…æ³
        df['è²¨å“æ¢ç¢¼'] = df['è²¨å“æ¢ç¢¼'].astype(str).str.strip().str.replace(r'\.0+$', '', regex=True)
        for col in ['å…¥è²¨åƒ¹', 'å…¥è²¨é‡']:
            df[col] = df[col].astype(str).str.replace(r'[^\d.]', '', regex=True)
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        df['å…¥è²¨é‡'] = df['å…¥è²¨é‡'].astype(int)
        
        # 5. æˆæœ¬åŠ æˆé‚è¼¯
        multiplier_flag = str(supplier_config.get('æˆæœ¬ä¹˜ä»¥1.2', '')).strip()
        if multiplier_flag in ['æ˜¯', 'Yes', 'TRUE', 'True', '1']:
            logger.info("   ğŸ’° åŸ·è¡Œæˆæœ¬åŠ æˆ (x1.2)")
            df['å…¥è²¨åƒ¹'] = df['å…¥è²¨åƒ¹'] * 1.2
            df['å…¥è²¨åƒ¹'] = df['å…¥è²¨åƒ¹'].round(2)

        # 6. è£œé½Šæ¬„ä½
        df['ä¾›æ‡‰å•†åç¨±'] = supplier_name  # å¡«å…¥è­˜åˆ¥åˆ°çš„ä¾›æ‡‰å•†åç¨±
        df['åº—è™Ÿ'] = 'S1'
        df['å…¥è²¨æ—¥æœŸ'] = datetime.now().strftime('%Y%m%d')
        df['æ”¶æ“šå–®è™Ÿ'] = ''
        df['ä¾›æ‡‰å•†ç·¨è™Ÿ'] = '001'
        df['å‚™è¨»'] = ''
        df['ç‹€æ…‹'] = ''
        df['è²¨å“ç·¨è™Ÿ'] = df['è²¨å“æ¢ç¢¼']

        df = df[ (df['è²¨å“æ¢ç¢¼'] != '') & (df['è²¨å“æ¢ç¢¼'] != 'nan') & (df['å…¥è²¨é‡'] > 0) ]
        return df, supplier_name

    def _rename_columns_strict(self, df: pd.DataFrame, config: pd.Series) -> pd.DataFrame:
        """æ ¹æ“šè¨­å®šæª”ç²¾ç¢ºæ”¹å"""
        target_map = {
            "è²¨å“æ¢ç¢¼": config.get("è²¨å“æ¢ç¢¼"),
            "å…¥è²¨åƒ¹": config.get("å…¥è²¨åƒ¹"),
            "å…¥è²¨é‡": config.get("å…¥è²¨é‡"),
            "è²¨å“åç¨±": config.get("è²¨å“åç¨±")
        }

        reverse_map = {}
        for target, source in target_map.items():
            if pd.notna(source):
                reverse_map[str(source).strip().lower()] = target
        
        new_columns = {}
        for col in df.columns:
            if str(col).strip().lower() in reverse_map:
                new_columns[col] = reverse_map[str(col).strip().lower()]
        
        return df.rename(columns=new_columns)


# --- ç”¢å“é©—è­‰å™¨ ---
class ProductValidator:
    def __init__(self, stock_csv_path: str):
        """
        åˆå§‹åŒ–ç”¢å“é©—è­‰å™¨ï¼Œè®€å– POS åº«å­˜è¨˜éŒ„
        
        Args:
            stock_csv_path: DetailGoodsStockToday.csv çš„è·¯å¾‘
        """
        self.stock_csv_path = Path(stock_csv_path)
        self.productcode_set = set()
        self.barcode_set = set()
        self._load_stock_data()
    
    def _load_stock_data(self):
        """è®€å–åº«å­˜ CSV ä¸¦å»ºç«‹æŸ¥æ‰¾é›†åˆ"""
        if not self.stock_csv_path.exists():
            logger.warning(f"âš ï¸ åº«å­˜æª”æ¡ˆä¸å­˜åœ¨: {self.stock_csv_path}")
            return
        
        try:
            # è®€å– CSVï¼Œä½¿ç”¨å­—ä¸²é¡å‹é¿å…æ ¼å¼å•é¡Œ
            df = pd.read_csv(self.stock_csv_path, dtype=str, encoding='utf-8-sig')
            
            # æå– ProductCode å’Œ Barcode æ¬„ä½
            if 'ProductCode' in df.columns:
                # æ¸…æ´—ä¸¦è½‰æ›ç‚ºé›†åˆï¼šå»é™¤ç©ºç™½ã€è™•ç† .0 çµå°¾ã€éæ¿¾ç©ºå€¼
                productcodes = df['ProductCode'].astype(str).str.strip().str.replace(r'\.0+$', '', regex=True)
                self.productcode_set = {code for code in productcodes if code and code.lower() != 'nan'}
            
            if 'Barcode' in df.columns:
                # æ¸…æ´—ä¸¦è½‰æ›ç‚ºé›†åˆï¼šå»é™¤ç©ºç™½ã€è™•ç† .0 çµå°¾ã€éæ¿¾ç©ºå€¼
                barcodes = df['Barcode'].astype(str).str.strip().str.replace(r'\.0+$', '', regex=True)
                self.barcode_set = {code for code in barcodes if code and code.lower() != 'nan'}
            
            logger.info(f"âœ… å·²è¼‰å…¥åº«å­˜è¨˜éŒ„: ProductCode {len(self.productcode_set)} ç­†, Barcode {len(self.barcode_set)} ç­†")
            
        except Exception as e:
            logger.error(f"âŒ è®€å–åº«å­˜æª”æ¡ˆå¤±æ•—: {e}")
    
    def validate_products(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        é©—è­‰ç”¢å“æ˜¯å¦å­˜åœ¨æ–¼ POS ç³»çµ±ä¸­
        
        Args:
            df: æ¸…æ´—å¾Œçš„æ”¶æ“š DataFrameï¼Œå¿…é ˆåŒ…å«ã€Œè²¨å“æ¢ç¢¼ã€æ¬„ä½
        
        Returns:
            Tuple[pd.DataFrame, pd.DataFrame]: 
            - matched_df: æ‰¾åˆ° ProductCode å°æ‡‰çš„è¨˜éŒ„ï¼ˆæ­£å¸¸è™•ç†ï¼‰
            - unmatched_df: æ‰¾ä¸åˆ°å°æ‡‰çš„è¨˜éŒ„ï¼ŒåŒ…å«ã€Œè™•ç†åŸå› ã€æ¬„ä½
        """
        if df.empty or 'è²¨å“æ¢ç¢¼' not in df.columns:
            return pd.DataFrame(), pd.DataFrame()
        
        # è¤‡è£½ DataFrame ä»¥é¿å…ä¿®æ”¹åŸå§‹è³‡æ–™
        df = df.copy()
        
        # æº–å‚™æ¯”å°ç”¨çš„æ¢ç¢¼ï¼ˆæ¸…æ´—æ ¼å¼ï¼‰
        df['_barcode_clean'] = df['è²¨å“æ¢ç¢¼'].astype(str).str.strip().str.replace(r'\.0+$', '', regex=True)
        
        # åˆå§‹åŒ–åŒ¹é…ç‹€æ…‹å’ŒåŸå› å­—å…¸
        matched_mask = pd.Series([False] * len(df), index=df.index)
        reason_dict = {}  # ä½¿ç”¨å­—å…¸å„²å­˜æ¯å€‹ç´¢å¼•å°æ‡‰çš„åŸå› 
        
        # çµ±è¨ˆç”¨
        matched_count = 0
        barcode_only_count = 0
        unmatched_count = 0
        
        for idx, row in df.iterrows():
            barcode = row['_barcode_clean']
            
            # è·³éç©ºå€¼
            if not barcode or barcode.lower() == 'nan':
                continue
            
            # æƒ…æ³1: æ‰¾åˆ° ProductCodeï¼ˆå®Œå…¨åŒ¹é…ï¼‰
            if barcode in self.productcode_set:
                matched_mask[idx] = True
                matched_count += 1
            # æƒ…æ³2: åªæ‰¾åˆ° Barcodeï¼ˆéƒ¨åˆ†åŒ¹é…ï¼‰
            elif barcode in self.barcode_set:
                reason_dict[idx] = 'å…±ç”¨æ¢ç¢¼ï¼Œéœ€äººæ‰‹é¸æ“‡é¡è‰²æˆ–å¤§å°'
                barcode_only_count += 1
            # æƒ…æ³3: å®Œå…¨æ‰¾ä¸åˆ°
            else:
                reason_dict[idx] = 'å¯èƒ½æ˜¯æ¢ç¢¼éŒ¯èª¤æˆ–æ–°è²¨å“'
                unmatched_count += 1
        
        # åˆ†é›¢æ•¸æ“š
        matched_df = df[matched_mask].copy()
        unmatched_df = df[~matched_mask].copy()
        
        # ç§»é™¤è‡¨æ™‚æ¬„ä½
        if '_barcode_clean' in matched_df.columns:
            matched_df = matched_df.drop(columns=['_barcode_clean'])
        if '_barcode_clean' in unmatched_df.columns:
            unmatched_df = unmatched_df.drop(columns=['_barcode_clean'])
        
        # ç‚º unmatched_df åŠ å…¥è™•ç†åŸå› æ¬„ä½
        if not unmatched_df.empty:
            # ä½¿ç”¨ç´¢å¼•å°æ‡‰çš„åŸå› 
            unmatched_df['è™•ç†åŸå› '] = unmatched_df.index.map(reason_dict).fillna('')
        
        # è¨˜éŒ„çµ±è¨ˆ
        logger.info(f"   ğŸ“Š ç”¢å“é©—è­‰çµæœ:")
        logger.info(f"      âœ… æ‰¾åˆ° ProductCode: {matched_count} ç­†")
        logger.info(f"      âš ï¸ åªæ‰¾åˆ° Barcode: {barcode_only_count} ç­†")
        logger.info(f"      âŒ å®Œå…¨æ‰¾ä¸åˆ°: {unmatched_count} ç­†")
        
        return matched_df, unmatched_df


# --- æª”æ¡ˆè¼¸å‡ºå™¨ ---
class ReceiptExporter:
    def __init__(self, base_dir: str = "workspace"):
        self.output_root = Path(base_dir) / "output"

        self.pos_dir = self.output_root / "pos_import" # å­˜æ”¾ POS æ ¼å¼çš„ XLS
        
        self.pos_dir.mkdir(parents=True, exist_ok=True)

    def save_pos_excel(self, df: pd.DataFrame, original_filename: str):
        """ç”¢ç”Ÿ POS ç³»çµ±å°ˆç”¨çš„èˆŠç‰ˆ .xls æ ¼å¼ (å­—ä¸²æ¨¡å¼)"""
        # å®šç¾©æ¨¡æ¿ (ä¾ç…§ä½ çš„éœ€æ±‚)
        # éµå€¼ (0-12) å°æ‡‰ Excel çš„ç¬¬ A-M æ¬„
        Instock_template = {
            0: [
                'MBA POS å…¥è²¨è¡¨', '', 
                'è«‹ä¸è¦ä¿®æ”¹æ­¤å…¥è²¨è¡¨ä¹‹æ ¼å¼!! å¦‚æ­¤å…¥è²¨è¡¨ä¹‹æ ¼å¼è¢«ä¿®æ”¹, å¯èƒ½æœƒå°è‡´ç³»çµ±ä¸èƒ½åŒ¯å…¥æ­¤è¡¨ä¸­çš„è³‡æ–™!!', 
                'ç³»çµ±åªæœƒæª¢æŸ¥ä¸¦æŠŠ è²¨è™Ÿ/ æ¢ç¢¼,  å…¥è²¨åƒ¹,  å…¥è²¨é‡, åº—è™Ÿ, å…¥è²¨æ—¥æœŸ, æ”¶æ“šå–®è™Ÿ åŠ ä¾›æ‡‰å•†ç·¨è™Ÿ  è³‡æ–™åŒ¯å…¥ç³»çµ±.  è²¨å“åŠä¾›æ‡‰å•†åç¨±åªä¾›å®¢äººä½œåƒè€ƒ.', 
                'å¯åœ¨ä¸‹è¡¨ åªè¼¸å…¥è²¨å“ç·¨è™Ÿæˆ–è²¨ å“æ¢ç¢¼.   å¦‚åœ¨ä¸‹è¡¨åŒæ™‚è¼¸å…¥è²¨å“ç·¨è™ŸåŠè²¨å“æ¢ç¢¼, ç³»çµ±æœƒä»¥è²¨å“ç·¨è™Ÿç‚ºæº–.', 
                'è«‹ç•™æ„, å…¥è²¨æ—¥æœŸæ ¼å¼ç‚º (å¹´å¹´å¹´å¹´æœˆæœˆæ—¥æ—¥), å³ä»Šå¤©çš„æ—¥æœŸç‚º 20250315', 
                '', '', '', '', '', '', '', '', 'è²¨å“ç·¨è™Ÿ'
            ],
            1: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'è²¨å“æ¢ç¢¼'],
            2: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'è²¨å“åç¨±'],
            3: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'å…¥è²¨åƒ¹'],
            4: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'å…¥è²¨é‡'],
            5: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'åº—è™Ÿ'],
            6: ['Ver:3.2', '', '', '', '', '', '', '', '', '', '', '', '', '', 'å…¥è²¨æ—¥æœŸ'],
            7: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'æ”¶æ“šå–®è™Ÿ'],
            8: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'ä¾›æ‡‰å•†ç·¨è™Ÿ'],
            9: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'ä¾›æ‡‰å•†åç¨±'],
            10: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'å‚™è¨»'],
            11: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'ç‹€æ…‹'],
            12: ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'ç³»çµ±å‚™è¨»']
        }

        # 1. æº–å‚™ POS ç³»çµ±è¦æ±‚çš„æ¬„ä½é †åº (å‹™å¿…èˆ‡ Template Key 0~12 å°æ‡‰)
        target_columns = [
            'è²¨å“ç·¨è™Ÿ', 'è²¨å“æ¢ç¢¼', 'è²¨å“åç¨±', 'å…¥è²¨åƒ¹', 'å…¥è²¨é‡',
            'åº—è™Ÿ', 'å…¥è²¨æ—¥æœŸ', 'æ”¶æ“šå–®è™Ÿ', 'ä¾›æ‡‰å•†ç·¨è™Ÿ', 'ä¾›æ‡‰å•†åç¨±',
            'å‚™è¨»', 'ç‹€æ…‹', 'ç³»çµ±å‚™è¨»'
        ]

        # ç¢ºä¿ DataFrame æŒ‰ç…§é€™å€‹é †åºæ’åˆ—ï¼Œç¼ºå°‘çš„æ¬„ä½æœƒåœ¨ Cleaner éšæ®µè£œé½Š
        # è‹¥æœ‰è¬ä¸€ç¼ºå°‘çš„ï¼Œé€™è£¡è£œä¸Šç©ºå­—ä¸²ä»¥å…å ±éŒ¯
        for col in target_columns:
            if col not in df.columns:
                df[col] = ''
        
        df_export = df[target_columns].copy()

        # 2. å»ºç«‹ Excel
        workbook = xlwt.Workbook(encoding='utf-8')
        sheet = workbook.add_sheet('Sheet1')

        # 3. å¯«å…¥æ¨¡æ¿ (Template)
        # Template çµæ§‹ï¼šKey æ˜¯ Column Indexï¼ŒValue æ˜¯è©² Column çš„ Rows List
        for col_idx, row_data_list in Instock_template.items():
            for row_idx, cell_value in enumerate(row_data_list):
                # å¼·åˆ¶è½‰å­—ä¸²
                sheet.write(row_idx, col_idx, str(cell_value))

        # 4. å¯«å…¥æ•¸æ“š (Data)
        # è³‡æ–™å¾æ¨¡æ¿æœ€é•·çš„é‚£ä¸€è¡Œä¹‹å¾Œé–‹å§‹å¯«å…¥
        start_row = max(len(row) for row in Instock_template.values())
        
        for i, row_data in enumerate(df_export.values):
            for j, cell_value in enumerate(row_data):
                # å¼·åˆ¶è½‰å­—ä¸² (str)ï¼Œç¢ºä¿ POS ç³»çµ±ç›¸å®¹æ€§
                sheet.write(start_row + i, j, str(cell_value))

        # 5. å­˜æª”
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"POS_{Path(original_filename).stem}_{timestamp}.xls"
        save_path = self.pos_dir / filename
        
        workbook.save(str(save_path))
        logger.info(f"   ğŸ’¾ POS åŒ¯å…¥æª”: {filename}")
    
    def save_unmatched_excel(self, df: pd.DataFrame, supplier_name: str, base_dir: str = "workspace"):
        """
        å°‡æ‰¾ä¸åˆ°å°æ‡‰çš„ç”¢å“å­˜æˆå¾…è™•ç† Excel æª” (.xlsx)
        
        Args:
            df: åŒ…å«ã€Œè™•ç†åŸå› ã€æ¬„ä½çš„å¾…è™•ç† DataFrame
            supplier_name: è­˜åˆ¥åˆ°çš„ä¾›æ‡‰å•†åç¨±
            base_dir: å·¥ä½œç›®éŒ„
        """
        if df.empty:
            return
        
        # ç¢ºä¿ pending è³‡æ–™å¤¾å­˜åœ¨
        pending_dir = Path(base_dir) / "pending"
        pending_dir.mkdir(parents=True, exist_ok=True)
        
        # æº–å‚™è¼¸å‡ºæ¬„ä½é †åºï¼ˆåŒ…å«è™•ç†åŸå› ï¼‰
        output_columns = [
            'è²¨å“æ¢ç¢¼', 'è²¨å“åç¨±', 'å…¥è²¨åƒ¹', 'å…¥è²¨é‡',
            'ä¾›æ‡‰å•†åç¨±', 'åº—è™Ÿ', 'å…¥è²¨æ—¥æœŸ', 'æ”¶æ“šå–®è™Ÿ', 
            'ä¾›æ‡‰å•†ç·¨è™Ÿ', 'å‚™è¨»', 'ç‹€æ…‹', 'è²¨å“ç·¨è™Ÿ', 'è™•ç†åŸå› '
        ]
        
        # ç¢ºä¿æ‰€æœ‰æ¬„ä½éƒ½å­˜åœ¨
        for col in output_columns:
            if col not in df.columns:
                df[col] = ''
        
        # æŒ‰ç…§æŒ‡å®šé †åºæ’åˆ—æ¬„ä½
        df_export = df[output_columns].copy()
        
        # å­˜æª” - ä½¿ç”¨æ–°æ ¼å¼ï¼š{ä¾›æ‡‰å•†åç¨±}éœ€è¦äººæ‰‹è™•ç†{æ—¥æœŸ}.xlsx
        date_str = datetime.now().strftime("%Y%m%d")
        # æ¸…ç†ä¾›æ‡‰å•†åç¨±ï¼Œç§»é™¤å¯èƒ½å°è‡´æª”æ¡ˆåå•é¡Œçš„å­—å…ƒ
        safe_supplier_name = supplier_name.replace('/', '_').replace('\\', '_').replace(':', '_').replace('*', '_').replace('?', '_').replace('"', '_').replace('<', '_').replace('>', '_').replace('|', '_')
        filename = f"{safe_supplier_name}éœ€è¦äººæ‰‹è™•ç†{date_str}.xlsx"
        save_path = pending_dir / filename
        
        try:
            # ä½¿ç”¨ pandas çš„ to_excel è¼¸å‡º .xlsx æ ¼å¼
            df_export.to_excel(save_path, index=False, engine='openpyxl')
            logger.info(f"   ğŸ“‹ å¾…è™•ç†æª”: {filename}")
            logger.info(f"      åŸå› çµ±è¨ˆ: {df_export['è™•ç†åŸå› '].value_counts().to_dict()}")
        except ImportError:
            # å¦‚æœæ²’æœ‰ openpyxlï¼Œå˜—è©¦ä½¿ç”¨ xlsxwriter
            try:
                df_export.to_excel(save_path, index=False, engine='xlsxwriter')
                logger.info(f"   ğŸ“‹ å¾…è™•ç†æª”: {filename}")
                logger.info(f"      åŸå› çµ±è¨ˆ: {df_export['è™•ç†åŸå› '].value_counts().to_dict()}")
            except ImportError:
                logger.error("âŒ éœ€è¦å®‰è£ openpyxl æˆ– xlsxwriter æ‰èƒ½è¼¸å‡º .xlsx æ ¼å¼")
                logger.info("   è«‹åŸ·è¡Œ: pip install openpyxl")
        except Exception as e:
            logger.error(f"âŒ å„²å­˜å¾…è™•ç†æª”å¤±æ•—: {e}")

def main():

    base_dir = "workspace"
    # 1. è®€å–è¨­å®š
    config_mgr = ConfigManager(Path(base_dir))
    config_df = config_mgr.load_config()
    
    loader = BatchReceiptLoader(base_dir)
    cleaner = ReceiptCleaner(config_df)
    exporter = ReceiptExporter(base_dir)

    # è®€å–ä¸¦é©—è­‰åº«å­˜æ•¸æ“šæº
    input_stock = "data/processed/DetailGoodsStockToday.csv"
    if not os.path.exists(input_stock):
        logger.error("âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æ•¸æ“šæºã€‚")
        return
    
    # å»ºç«‹ç”¢å“é©—è­‰å™¨
    validator = ProductValidator(input_stock)

    logger.info("ğŸš€ é–‹å§‹æ‰¹æ¬¡è™•ç†...")
    
    # æœå°‹é—œéµå­—ï¼šå¾è¨­å®šæª”è£¡çš„ 4 å€‹é—œéµæ¬„ä½æŠ“å­—
    search_keywords = []
    if not config_df.empty:
        target_cols = ["è²¨å“æ¢ç¢¼", "å…¥è²¨åƒ¹", "å…¥è²¨é‡", "è²¨å“åç¨±"]
        for col in target_cols:
            if col in config_df.columns:
                keywords = config_df[col].dropna().unique().tolist()
                search_keywords.extend([k for k in keywords if k.lower() != 'nan' and k.strip()])
    
    # è‹¥ Config æ²’æ±è¥¿ï¼Œçµ¦å€‹åŸºæœ¬é è¨­å€¼ä»¥å…ç¨‹å¼è·‘ä¸å‹•
    if not search_keywords:
        logger.warning("âš ï¸ Config ä¸­ç„¡é—œéµå­—ï¼Œè«‹è¨­å®šä¾›æ‡‰å•†è¨­å®šæª”ï¼")
        return

    # 2. é–‹å§‹è·‘æª”æ¡ˆ
    for file_path in loader.get_pending_files():
        raw_header_df, raw_data_df = loader.smart_load(file_path, search_keywords)
        
        if not raw_data_df.empty:
            clean_df, supplier_name = cleaner.process(raw_data_df)
            
            if clean_df is not None:
                # ç”¢å“é©—è­‰ï¼šåˆ†é›¢æœ‰å°æ‡‰å’Œæ‰¾ä¸åˆ°çš„ç”¢å“
                matched_df, unmatched_df = validator.validate_products(clean_df)
                
                # è™•ç†æœ‰å°æ‡‰çš„ç”¢å“ï¼ˆæ­£å¸¸åŒ¯å‡º POS æª”ï¼‰
                if not matched_df.empty:
                    exporter.save_pos_excel(matched_df, file_path.name)
                    logger.info(f"   âœ… å·²åŒ¯å‡º {len(matched_df)} ç­†ç”¢å“åˆ° POS åŒ¯å…¥æª”")
                
                # è™•ç†æ‰¾ä¸åˆ°å°æ‡‰çš„ç”¢å“ï¼ˆå­˜å¾…è™•ç†æª”ï¼‰
                if not unmatched_df.empty:
                    exporter.save_unmatched_excel(unmatched_df, supplier_name, base_dir)
                    logger.info(f"   âš ï¸ å·²æ¨™è¨˜ {len(unmatched_df)} ç­†ç”¢å“å¾…äººå·¥è™•ç†")
                
                # æ‰€æœ‰è™•ç†éçš„åŸå§‹æ”¶æ“šéƒ½æ­¸æª”åˆ° processed
                loader.archive_file(file_path)
                logger.info(f"   ğŸ“¦ åŸå§‹æ”¶æ“šå·²æ­¸æª”")
            else:
                logger.error("   âŒ æ¸…æ´—å¤±æ•— (æœªè­˜åˆ¥æˆ–æ ¼å¼éŒ¯èª¤)")
        
    logger.info("-" * 30)
    logger.info("ç¨‹å¼åŸ·è¡Œå®Œæˆï¼Œç­‰å¾…ç”¨æˆ¶ç¢ºèª...")

# --- ä¸»ç¨‹å¼ ---
if __name__ == "__main__":
    main()