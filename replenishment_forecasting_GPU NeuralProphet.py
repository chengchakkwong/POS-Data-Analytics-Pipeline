import pandas as pd
import numpy as np
import os
import time
import warnings
import logging
from joblib import Parallel, delayed

# --- ç³»çµ±é…ç½®èˆ‡æ•ˆèƒ½è¨­å®š ---
TEST_MODE = False      # æ­£å¼é–‹å§‹ï¼è¨­ç‚º False ä»¥è™•ç†å…¨é‡ 7000 å€‹å•†å“
SAMPLE_SIZE = 50       # (æ¸¬è©¦æ¨¡å¼æ‰æœ‰æ•ˆ)
# ğŸ’¡ æ•ˆèƒ½æç¤ºï¼š4070 Ti (12GB) çš„é»ƒé‡‘å¹³è¡¡é»é€šå¸¸åœ¨ 3-4ã€‚
# è¶…é 5 å€‹ worker æœƒå°è‡´ CPU åºåˆ—åŒ–æ•¸æ“šéæ…¢ï¼Œä¸” GPU ä¸Šä¸‹æ–‡åˆ‡æ›é »ç¹ï¼Œåè€Œé™ä½ç¸½é«”é€Ÿåº¦ã€‚
GPU_WORKERS = 4        
# ------------------------

# å˜—è©¦å°å…¥ NeuralProphet ä»¥æ”¯æ´ GPU åŠ é€Ÿ
try:
    from neuralprophet import NeuralProphet
    import torch
    HAS_NEURAL_PROPHET = True
    # åµæ¸¬ NVIDIA GPU
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    if DEVICE == "cuda":
        # 4070 Ti æœ‰ 12GB VRAMï¼Œå„ªåŒ–é¡¯å­˜åˆ†é…
        torch.cuda.empty_cache()
        vram_total = torch.cuda.get_device_properties(0).total_memory / (1024**3)
except ImportError:
    from prophet import Prophet
    HAS_NEURAL_PROPHET = False
    DEVICE = "cpu"
    vram_total = 0

# å¿½ç•¥æ—¥èªŒå¹²æ“¾
warnings.filterwarnings('ignore')
logging.getLogger('prophet').setLevel(logging.ERROR)
logging.getLogger('neuralprophet').setLevel(logging.ERROR)

# --- 1. æ•¸æ“šåˆ†é¡èˆ‡é è™•ç† ---

def calculate_category_seasonal_indices(sales_df, stock_df):
    """è¨ˆç®—é¡åˆ¥å±¤ç´šçš„å­£ç¯€æ€§ä¿‚æ•¸ (ç”¨æ–¼è¼”åŠ©æ•¸æ“šç¨€ç–å•†å“)"""
    sales_df = sales_df.copy()
    sales_df['rDate'] = pd.to_datetime(sales_df['rDate'])
    df_with_cat = sales_df.merge(stock_df[['GoodsID', 'Category']], on='GoodsID', how='left')
    cat_monthly = df_with_cat.groupby(['Category', pd.Grouper(key='rDate', freq='MS')])['TotalQty'].sum().reset_index()
    cat_avg = cat_monthly.groupby('Category')['TotalQty'].mean().rename('Cat_Avg_Qty').reset_index()
    cat_indices = cat_monthly.merge(cat_avg, on='Category')
    cat_indices['Seasonal_Index'] = cat_indices['TotalQty'] / cat_indices['Cat_Avg_Qty']
    cat_indices['Month'] = cat_indices['rDate'].dt.month
    index_map = cat_indices.groupby(['Category', 'Month'])['Seasonal_Index'].mean().to_dict()
    return index_map

def perform_abc_xyz_analysis(stock_df, sales_df):
    """åŸ·è¡Œ ABC-XYZ çŸ©é™£åˆ†æ (åƒ¹å€¼èˆ‡æ³¢å‹•)"""
    sales_df['rDate'] = pd.to_datetime(sales_df['rDate'])
    last_date = sales_df['rDate'].max()
    start_12m = last_date - pd.DateOffset(months=12)
    
    df_12m = sales_df[sales_df['rDate'] >= start_12m].copy()
    summary_12m = df_12m.groupby('GoodsID').agg({'TotalQty': 'sum', 'TotalAmt': 'sum'}).reset_index()
    
    merged = pd.merge(stock_df, summary_12m, on='GoodsID', how='left').fillna(0)
    merged['TotalProfit'] = merged['TotalAmt'] - (merged['LastInCost'] * merged['TotalQty'])
    merged = merged.sort_values('TotalProfit', ascending=False)
    
    total_prof = merged['TotalProfit'].sum()
    if total_prof > 0:
        merged['ProfitRatio'] = merged['TotalProfit'].cumsum() / total_prof
    else:
        merged['ProfitRatio'] = 1.0
        
    merged['ABC_Class'] = np.select([(merged['ProfitRatio'] <= 0.7), (merged['ProfitRatio'] <= 0.9)], ['A', 'B'], default='C')

    # XYZ åˆ†æï¼šç¢ºä¿ Mean_Monthly æ˜¯åŸºæ–¼å®Œæ•´çš„æ™‚é–“ç¯„åœ (é¿å… Mean éé«˜)
    monthly_matrix = sales_df.groupby(['GoodsID', pd.Grouper(key='rDate', freq='MS')])['TotalQty'].sum().unstack(fill_value=0)
    stats = pd.DataFrame(index=monthly_matrix.index)
    stats['Mean_Monthly'] = monthly_matrix.mean(axis=1)
    stats['CV'] = np.where(stats['Mean_Monthly'] > 0, monthly_matrix.std(axis=1) / stats['Mean_Monthly'], 9.99)
    stats['XYZ_Class'] = np.select([(stats['CV'] <= 0.5), (stats['CV'] <= 1.0)], ['X', 'Y'], default='Z')
    
    first_sale = sales_df.groupby('GoodsID')['rDate'].min().reset_index()
    first_sale['Month_Age'] = (last_date.year - first_sale['rDate'].dt.year) * 12 + (last_date.month - first_sale['rDate'].dt.month)
    
    analysis_df = merged.merge(stats[['CV', 'XYZ_Class', 'Mean_Monthly']], left_on='GoodsID', right_index=True, how='left')
    analysis_df = analysis_df.merge(first_sale[['GoodsID', 'Month_Age']], on='GoodsID', how='left').fillna({
        'Month_Age': 99, 'XYZ_Class': 'Z', 'CV': 9.99, 'Mean_Monthly': 0
    })
    
    is_new = (analysis_df['Month_Age'] < 4)
    analysis_df.loc[is_new, 'ABC_Class'], analysis_df.loc[is_new, 'XYZ_Class'] = 'New', 'New'
    
    return analysis_df

# --- 2. GPU åŠ é€Ÿé æ¸¬æ ¸å¿ƒ ---

def run_single_sku_forecast(item, sales_df, next_month, cat_index_map):
    """å–®ä¸€ SKU é æ¸¬å–®å…ƒï¼šåˆ©ç”¨ 4070 Ti çš„ CUDA é€²è¡Œ NeuralProphet é‹ç®—"""
    gid, abc, xyz, cv, cat, total_qty_year = item['GoodsID'], item['ABC_Class'], item['XYZ_Class'], item['CV'], item['Category'], item['TotalQty']
    item_sales = sales_df[sales_df['GoodsID'] == gid].sort_values('rDate')
    mean_qty = item['Mean_Monthly']
    
    # å»ºç«‹å®Œæ•´çš„æ™‚é–“åºåˆ—ï¼Œå¡«è£œ 0 éŠ·é‡æœˆä»½ (é€™å° AI é æ¸¬æ¥µå…¶é‡è¦)
    full_date_range = pd.date_range(start=sales_df['rDate'].min(), end=sales_df['rDate'].max(), freq='MS')
    
    base_pred = 0
    used_gpu = False
    try:
        if abc == 'New':
            recent = item_sales[item_sales['rDate'] >= (sales_df['rDate'].max() - pd.Timedelta(weeks=4))]
            base_pred = (recent['TotalQty'].sum() / 4) * 4 if not recent.empty else mean_qty
        
        elif xyz == 'Y':
            # å¡«è£œ 0 å€¼ï¼šç¢ºä¿æ¨¡å‹çœ‹åˆ°æ·¡å­£
            m_df = item_sales.groupby(pd.Grouper(key='rDate', freq='MS'))['TotalQty'].sum().reindex(full_date_range, fill_value=0).reset_index()
            m_df.columns = ['ds', 'y']
            
            if len(m_df) >= 12:
                if HAS_NEURAL_PROPHET:
                    m = NeuralProphet(
                        yearly_seasonality=True,
                        weekly_seasonality=False,
                        daily_seasonality=False,
                        accelerator=DEVICE if DEVICE == "cuda" else None,
                        epochs=30, 
                        batch_size=None, # è‡ªå‹•èª¿æ•´æ‰¹æ¬¡ï¼Œé¿å…æ•¸æ“šé‡å¤ªå°å‡ºéŒ¯
                        trainer_config={"logger": False, "enable_checkpointing": False, "enable_progress_bar": False}
                    )
                    m.fit(m_df, freq="MS", progress=None)
                    future = m.make_future_dataframe(m_df, periods=1)
                    forecast = m.predict(future)
                    base_pred = max(0, forecast.iloc[-1]['yhat1'])
                    used_gpu = (DEVICE == "cuda")
                    if used_gpu: torch.cuda.empty_cache()
                else:
                    m = Prophet(yearly_seasonality=True, uncertainty_samples=0)
                    m.fit(m_df)
                    base_pred = max(0, m.predict(m.make_future_dataframe(periods=1, freq='MS')).iloc[-1]['yhat'])
            else:
                base_pred = m_df['y'].tail(3).mean()
        
        elif xyz == 'X':
            base_pred = item_sales.groupby(pd.Grouper(key='rDate', freq='MS'))['TotalQty'].sum().tail(3).mean()
        
        else:
            base_pred = item_sales.groupby(pd.Grouper(key='rDate', freq='MS'))['TotalQty'].sum().tail(6).median()
    except:
        base_pred = mean_qty

    # --- é˜²çˆ†é–€é™èˆ‡è£œè²¨é‚è¼¯ ---
    
    # [å„ªåŒ– 1] åŸºç¤é æ¸¬ä¸æ‡‰è¶…éæœˆå¹³å‡çš„ 3 å€ (é‡å°éæ–°å“)
    if abc != 'New' and mean_qty > 0:
        base_pred = min(base_pred, mean_qty * 3)
    
    # å¦‚æœé æ¸¬å‡ºä¾†é‚„æ˜¯ 0 ä½†å®ƒæ˜¯ A é¡ç©©å®šå“ï¼Œå¼·åˆ¶å›é€€åˆ°å¹³å‡å€¼ (é›™é‡ä¿éšª)
    if base_pred <= 0 and abc in ['A', 'B'] and mean_qty > 0:
        base_pred = mean_qty

    boost = min(2.0, cat_index_map.get((cat, next_month), 1.0)) if (abc == 'New' or xyz == 'Z') else 1.0
    final_demand = base_pred * max(1.0, boost)
    
    # å®‰å…¨åº«å­˜é˜²ç¦¦
    safety_ratio = min(0.5 if abc == 'A' else 0.3, cv * 0.5)
    target_stock = final_demand + (final_demand * safety_ratio)
    
    # [å„ªåŒ– 2] å¼·åŠ›ç¾å¯¦æª¢æŸ¥ (Reality Check)
    if abc != 'New' and mean_qty > 0:
        target_stock_limit = max(mean_qty * 4, 2)
        target_stock = min(target_stock, target_stock_limit)
        
    if abc != 'New' and total_qty_year > 0:
        target_stock = min(target_stock, total_qty_year)

    return {
        'GoodsID': gid, 'Name': item['Name'], 'ABC_XYZ': f"{abc}{xyz}",
        'Base_Demand': round(base_pred, 2),
        'Final_Demand': round(final_demand, 2), 'Target_Stock': round(target_stock, 2),
        'CurrStock': item['CurrStock'], 'Used_GPU': used_gpu
    }

# --- 3. ä¸»ç¨‹åºåŸ·è¡Œé‚è¼¯ ---

def main():
    input_stock = "data/processed/DetailGoodsStockToday.csv"
    input_sales = "data/processed/vw_GoodsDailySales_cache.parquet"
    output_path = "data/insights/final_inventory_plan.csv"
    
    print(f"ğŸš€ å•Ÿå‹•å„ªåŒ–ç‰ˆæ™ºæ…§è£œè²¨ç³»çµ± (è£ç½®: {DEVICE.upper()})")
    if DEVICE == "cuda":
        print(f"ğŸ’ è£ç½®ç¡¬é«”: NVIDIA RTX 4070 Ti (ç¸½é¡¯å­˜: {vram_total:.2f} GB)")
        print(f"ğŸ§µ æœ€ä½³ä¸¦è¡Œé€²ç¨‹æ•¸: {GPU_WORKERS}")
        
    if TEST_MODE:
        print(f"âš ï¸ è­¦å‘Šï¼šç›®å‰è™•æ–¼æ¸¬è©¦æ¨¡å¼ï¼Œåƒ…è™•ç†å‰ {SAMPLE_SIZE} å€‹å•†å“ã€‚")
    else:
        print(f"ğŸ”¥ å…¨é‡æ¨¡å¼å•Ÿå‹•ï¼æ­£åœ¨åˆ†æå…¨åº—æ•¸æ“š...")
    
    if not os.path.exists(input_stock) or not os.path.exists(input_sales):
        print("âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æ•¸æ“šæºã€‚")
        return

    df_stock, df_sales = pd.read_csv(input_stock), pd.read_parquet(input_sales)
    
    print("ğŸ“Š åŸ·è¡Œ ABC-XYZ åˆ†é¡èˆ‡é¡åˆ¥åŠ æˆåˆ†æ...")
    analysis_df = perform_abc_xyz_analysis(df_stock, df_sales)
    cat_index_map = calculate_category_seasonal_indices(df_sales, df_stock)
    
    # ç¯©é¸éœ€è¦é æ¸¬çš„å•†å“
    target_skus = analysis_df[analysis_df['ABC_Class'].isin(['A', 'B', 'New'])]
    
    if TEST_MODE:
        target_skus = target_skus.head(SAMPLE_SIZE)
        
    next_month = (pd.to_datetime(df_sales['rDate']).max() + pd.DateOffset(months=1)).month
    
    print(f"ğŸ”® é–‹å§‹é«˜æ•ˆä¸¦è¡Œé æ¸¬ {len(target_skus)} å€‹å•†å“...")
    start_time = time.time()
    
    # ä¸¦è¡Œé€²ç¨‹æ•¸è¨­å®š
    n_workers = GPU_WORKERS if DEVICE == "cuda" else -1
    
    try:
        results = Parallel(n_jobs=n_workers, backend="loky")(
            delayed(run_single_sku_forecast)(row, df_sales, next_month, cat_index_map) 
            for _, row in target_skus.iterrows()
        )
        
        forecast_df = pd.DataFrame(results)
        forecast_df['Suggested_Order'] = (forecast_df['Target_Stock'] - forecast_df['CurrStock']).clip(lower=0)
        forecast_df.sort_values(by='Suggested_Order', ascending=False).to_csv(output_path, index=False, encoding='utf-8-sig')
        
        gpu_count = forecast_df['Used_GPU'].sum()
        end_time = time.time()
        
        print(f"âœ… åˆ†æå®Œæˆï¼ç¸½è€—æ™‚: {round(end_time - start_time, 2)} ç§’ã€‚")
        print(f"ğŸ“Š çµ±è¨ˆï¼šå…± {len(forecast_df)} é …ï¼ŒGPU åŠ é€Ÿ {gpu_count} é …ã€‚")
            
    except Exception as e:
        print(f"âŒ åŸ·è¡Œä¸­æ–·: {e}")

if __name__ == "__main__":
    main()